{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = 'https://raw.githubusercontent.com/rishika8910/IML/master/Housing%20Price%20data%20set.csv'\n",
    "dataset = pd.read_csv(dataset_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price = dataset['price']\n",
    "FloorArea = dataset['lotsize']\n",
    "NoOfBedrooms = dataset['bedrooms']\n",
    "NoOfBathrooms = dataset['bathrms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling on floor area\n",
    "Mean = np.mean(FloorArea)\n",
    "Max = max(FloorArea)\n",
    "Min = min(FloorArea)\n",
    "FloorArea_Scaled = []\n",
    "for i in FloorArea:\n",
    "\tFloorArea_Scaled.append((i - Mean) / (Max - Min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmenting the features\n",
    "FeaturesTrain = []\n",
    "for i in range(383):\n",
    "\tFeaturesTrain.append([1, FloorArea_Scaled[i], NoOfBedrooms[i], NoOfBathrooms[i]])\n",
    "PriceTrain = Price[:383]\n",
    "PriceTest = []\n",
    "FeaturesTest = []\n",
    "for i in range(383, len(Price)):\n",
    "\tFeaturesTest.append([1, FloorArea_Scaled[i], NoOfBedrooms[i], NoOfBathrooms[i]])\n",
    "\tPriceTest.append(Price[i])\n",
    "m = len(FeaturesTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeaturesTrain = []\n",
    "for i in range(383):\n",
    "\tFeaturesTrain.append([1, FloorArea_Scaled[i], NoOfBedrooms[i], NoOfBathrooms[i]])\n",
    "PriceTrain = Price[:383]\n",
    "PriceTest = []\n",
    "FeaturesTest = []\n",
    "for i in range(383, len(Price)):\n",
    "\tFeaturesTest.append([1, FloorArea_Scaled[i], NoOfBedrooms[i], NoOfBathrooms[i]])\n",
    "\tPriceTest.append(Price[i])\n",
    "m = len(FeaturesTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scaled batch gradient without regularisation\n"
     ]
    }
   ],
   "source": [
    "# Using scaled batch gradient without regularisation\n",
    "print(\"Using scaled batch gradient without regularisation\")\n",
    "LearningRate = 0.001\n",
    "m = len(FeaturesTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scaled batch gradient without regularisation\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate Slope to find coefficients\n",
    "def Slope(Coeff, FeaturesTrain, PriceTrain, ind):\n",
    "\tError = 0\n",
    "\tfor i in range(len(FeaturesTrain)):\n",
    "\t\titr = 0\n",
    "\t\tfor j in range(len(Coeff)):\n",
    "\t\t\titr = itr + Coeff[j] * FeaturesTrain[i][j]\n",
    "\t\tError += (itr - PriceTrain[i]) * FeaturesTrain[i][ind]\n",
    "\treturn Error\n",
    "\n",
    "# Using scaled batch gradient without regularisation\n",
    "print(\"Using scaled batch gradient without regularisation\")\n",
    "LearningRate = 0.001\n",
    "m = len(FeaturesTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial coefficients: \n",
      "[0, 0, 0, 0]\n",
      "Final coefficients are:\n",
      "[7730.872053867435, 8069.264303687423, 11077.015405893277, 18485.569122447192]\n"
     ]
    }
   ],
   "source": [
    "Coeff = [0, 0, 0, 0]\n",
    "print(\"Initial coefficients: \")\n",
    "print(Coeff)\n",
    "for i in range(5000):\n",
    "\tTempCoeff = Coeff.copy()\n",
    "\tfor j in range(len(Coeff)):\n",
    "\t\tTempCoeff[j] = TempCoeff[j] - ((LearningRate / m) * (Slope(Coeff, FeaturesTrain, PriceTrain, j)))\n",
    "\tCoeff = TempCoeff.copy()\n",
    "print(\"Final coefficients are:\")\n",
    "print(Coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute percentage error is : 18.30641888247704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding Mean absolute percentage error.\n",
    "Error = 0\n",
    "for i in range(len(FeaturesTest)):\n",
    "\tpredicted = 0\n",
    "\tfor j in range(len(Coeff)):\n",
    "\t  \tpredicted = predicted + Coeff[j] * FeaturesTest[i][j]\n",
    "\tError += abs(predicted - PriceTest[i]) / PriceTest[i]\n",
    "Error = (Error / len(FeaturesTest)) * 90\n",
    "print(\"Mean absolute percentage error is : \" + str(Error))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scaled batch gradient with regularisation\n",
      "Initial coefficients: \n",
      "[0, 0, 0, 0]\n",
      "Final coefficients are:\n",
      "[5037.585668619078, 11147.667574879839, 10378.580439168689, 22647.298983883848]\n"
     ]
    }
   ],
   "source": [
    "# Using scaled batch gradient with regularisation\n",
    "print(\"Using scaled batch gradient with regularisation\")\n",
    "LearningRate = 0.001\n",
    "LambdaParameter = -49\n",
    "Coeff = [0, 0, 0, 0]\n",
    "print(\"Initial coefficients: \")\n",
    "print(Coeff)\n",
    "for epochs in range(5000):\n",
    "\tTempCoeff = Coeff.copy()\n",
    "\tfor j in range(len(Coeff)):\n",
    "\t\tif (j == 0):\n",
    "\t\t\tTempCoeff[j] = TempCoeff[j] - ((LearningRate / m) * (Slope(Coeff, FeaturesTrain, PriceTrain, j)))\t\n",
    "\t\telse:\n",
    "\t\t\tTempCoeff[j] = (1 - LearningRate * LambdaParameter / m) * TempCoeff[j] - ((LearningRate / m) * (Slope(Coeff, FeaturesTrain, PriceTrain, j)))\n",
    "\tCoeff = TempCoeff.copy()\n",
    "print(\"Final coefficients are:\")\n",
    "print(Coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute percentage error is : 19.92701396456417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding Mean absolute percentage error.\n",
    "Error = 0\n",
    "for i in range(len(FeaturesTest)):\n",
    "\tpredicted = 0\n",
    "\tfor j in range(len(Coeff)):\n",
    "\t  \tpredicted = predicted + Coeff[j] * FeaturesTest[i][j]\n",
    "\tError += abs(predicted - PriceTest[i]) / PriceTest[i]\n",
    "Error = (Error / len(FeaturesTest)) * 100\n",
    "print(\"Mean absolute percentage error is : \" + str(Error))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SlopeStoch(Coeff,FeaturesTrain,ActualVal,ind):\n",
    "\titr = 0\n",
    "\tfor j in range(len(Coeff)):\n",
    "\t\titr = itr + Coeff[j]*FeaturesTrain[j]\n",
    "\treturn (itr - ActualVal) * FeaturesTrain[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Stochastic gradient without regularisation\n",
      "Initial coefficients: \n",
      "[0, 0, 0, 0]\n",
      "Final coefficients are:\n",
      "[18648.663069990776, 15073.501985961251, 15766.862790309351, 22357.23427068568]\n"
     ]
    }
   ],
   "source": [
    "# Using Scaled Stochastic gradient without regularisation.\n",
    "print(\"Using Stochastic gradient without regularisation\")\n",
    "\n",
    "LearningRate = 0.005\n",
    "Coeff = [0, 0, 0, 0]\n",
    "print(\"Initial coefficients: \")\n",
    "print(Coeff)\n",
    "\n",
    "for iter in range(10):\n",
    "\tfor i in range(len(PriceTrain)):\n",
    "\t\tTempCoeff = Coeff.copy()\n",
    "\t\tfor j in range(4):\n",
    "\t\t\tTempCoeff[j] = TempCoeff[j] - (LearningRate * (SlopeStoch(Coeff, FeaturesTrain[i], PriceTrain[i], j)))\n",
    "\t\tCoeff = TempCoeff.copy()\n",
    "\n",
    "print(\"Final coefficients are:\")\n",
    "print(Coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute percentage error is : 32.87903970192347\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding Mean absolute percentage error.\n",
    "Error = 0\n",
    "for i in range(len(FeaturesTest)):\n",
    "\tpredicted = 0\n",
    "\tfor j in range(len(Coeff)):\n",
    "\t  \tpredicted = predicted + Coeff[j] * FeaturesTest[i][j]\n",
    "\tError += abs(predicted - PriceTest[i]) / PriceTest[i]\n",
    "Error = (Error / len(FeaturesTest)) * 100\n",
    "print(\"Mean absolute percentage error is : \" + str(Error))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Stochastic gradient with regularisation\n",
      "Initial coefficients: \n",
      "[0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Using Scaled Stochastic gradient with regularisation.\n",
    "print(\"Using Stochastic gradient with regularisation\")\n",
    "\n",
    "LearningRate = 0.005\n",
    "LambdaParameter = 142000\n",
    "Coeff = [0, 0, 0, 0]\n",
    "print(\"Initial coefficients: \")\n",
    "print(Coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final coefficients are:\n",
      "[nan, nan, nan, nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-b2bb45e39970>:4: RuntimeWarning: overflow encountered in double_scalars\n",
      "  itr = itr + Coeff[j]*FeaturesTrain[j]\n",
      "<ipython-input-25-a6aefc53e166>:8: RuntimeWarning: overflow encountered in double_scalars\n",
      "  TempCoeff[j] = (1 - LearningRate * LambdaParameter) * TempCoeff[j] - (LearningRate * (SlopeStoch(Coeff, FeaturesTrain[i], PriceTrain[i], j)))\n",
      "<ipython-input-25-a6aefc53e166>:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  TempCoeff[j] = (1 - LearningRate * LambdaParameter) * TempCoeff[j] - (LearningRate * (SlopeStoch(Coeff, FeaturesTrain[i], PriceTrain[i], j)))\n"
     ]
    }
   ],
   "source": [
    "for iter in range(10):\n",
    "\tfor i in range(len(PriceTrain)):\n",
    "\t\tTempCoeff = Coeff.copy()\n",
    "\t\tfor j in range(4):\n",
    "\t\t\tif j == 0:\n",
    "\t\t\t\tTempCoeff[j] = TempCoeff[j] - (LearningRate * (SlopeStoch(Coeff, FeaturesTrain[i], PriceTrain[i], j)))\n",
    "\t\t\telse:\n",
    "\t\t\t\tTempCoeff[j] = (1 - LearningRate * LambdaParameter) * TempCoeff[j] - (LearningRate * (SlopeStoch(Coeff, FeaturesTrain[i], PriceTrain[i], j)))\n",
    "\t\tCoeff = TempCoeff.copy()\n",
    "\n",
    "print(\"Final coefficients are:\")\n",
    "print(Coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute percentage error is : nan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding Mean absolute percentage error.\n",
    "Error = 0\n",
    "for i in range(len(FeaturesTest)):\n",
    "\tpredicted = 0\n",
    "\tfor j in range(len(Coeff)):\n",
    "\t  \tpredicted = predicted + Coeff[j] * FeaturesTest[i][j]\n",
    "\tError += abs(predicted - PriceTest[i]) / PriceTest[i]\n",
    "Error = (Error / len(FeaturesTest)) * 100\n",
    "print(\"Mean absolute percentage error is : \" + str(Error))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Scaled Minibatch gradient without regularisation for batch size = 20\n"
     ]
    }
   ],
   "source": [
    "# Using Scaled Minibatch gradient without regularisation for batch size = 20\n",
    "print(\"Using Scaled Minibatch gradient without regularisation for batch size = 20\")\n",
    "\n",
    "BatchSize = 20;\n",
    "LearningRate = 0.002\n",
    "Coeff = [0, 0, 0, 0]\n",
    "NoOfBatches = math.ceil(len(PriceTrain) / BatchSize)\n",
    "equallyDiv = False\n",
    "if (len(PriceTrain) % BatchSize == 0):\n",
    "\tequallyDiv = True;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final coefficients are:\n",
      "[6340.552295015755, 2827.87646125345, 15916.90159915714, 10968.772912396124]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "\tfor batch in range(NoOfBatches):\n",
    "\t\tSummation = [0, 0, 0, 0]\n",
    "\t\tfor j in range(len(Coeff)):\n",
    "\t\t\tfor i in range(BatchSize):\n",
    "\t\t\t\tif (batch * BatchSize + i == len(FeaturesTrain)):\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\tPredictedValue = 0.0\n",
    "\t\t\t\tfor wj in range(len(Coeff)):\n",
    "\t\t\t\t\tPredictedValue += Coeff[wj] * FeaturesTrain[batch * BatchSize + i][wj]\n",
    "\t\t\t\tPredictedValue -= PriceTrain[batch * BatchSize + i]\n",
    "\t\t\t\tPredictedValue *= FeaturesTrain[batch * BatchSize + i][j]\n",
    "\t\t\t\tSummation[j] += PredictedValue;\n",
    "\n",
    "\t\tif (not equallyDiv and batch == NoOfBatches - 1):\n",
    "\t\t\tfor j in range(len(Summation)):\n",
    "\t\t\t\tCoeff[j] -= (Summation[j] / (len(PriceTrain) % BatchSize)) * LearningRate\n",
    "\t\telse:\n",
    "\t\t\tfor j in range(len(Summation)):\n",
    "\t\t\t\tCoeff[j] -= (Summation[j] / BatchSize) * LearningRate\n",
    "print(\"Final coefficients are:\")\n",
    "print(Coeff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute percentage error is : 20.275262089497147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding Mean absolute percentage error.\n",
    "Error = 0\n",
    "for i in range(len(FeaturesTest)):\n",
    "\tpredicted = 0\n",
    "\tfor j in range(len(Coeff)):\n",
    "\t  \tpredicted = predicted + Coeff[j] * FeaturesTest[i][j]\n",
    "\tError += abs(predicted - PriceTest[i]) / PriceTest[i]\n",
    "Error = (Error / len(FeaturesTest)) * 100\n",
    "print(\"Mean absolute percentage error is : \" + str(Error))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Scaled Minibatch gradient with regularisation for batch size = 20\n"
     ]
    }
   ],
   "source": [
    "# Using Scaled Minibatch gradient with regularisation for batch size = 20\n",
    "print(\"Using Scaled Minibatch gradient with regularisation for batch size = 20\")\n",
    "\n",
    "BatchSize = 20;\n",
    "LearningRate = 0.002\n",
    "LambdaParameter = -372\n",
    "Coeff = [0, 0, 0, 0]\n",
    "NoOfBatches = math.ceil(len(PriceTrain) / BatchSize)\n",
    "equallyDiv = False\n",
    "if (len(PriceTrain) % BatchSize == 0):\n",
    "\tequallyDiv = True;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final coefficients are:\n",
      "[888.9201243627547, 5168.211726125255, 17701.360814619125, 15202.387873756412]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "\tfor batch in range(NoOfBatches):\n",
    "\t\tSummation = [0, 0, 0, 0]\n",
    "\t\tfor j in range(len(Coeff)):\n",
    "\t\t\tfor i in range(BatchSize):\n",
    "\t\t\t\tif (batch * BatchSize + i == len(FeaturesTrain)):\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\tPredictedValue = 0.0\n",
    "\t\t\t\tfor wj in range(len(Coeff)):\n",
    "\t\t\t\t\tPredictedValue += Coeff[wj] * FeaturesTrain[batch * BatchSize + i][wj]\n",
    "\t\t\t\tPredictedValue -= PriceTrain[batch * BatchSize + i]\n",
    "\t\t\t\tPredictedValue *= FeaturesTrain[batch * BatchSize + i][j]\n",
    "\t\t\t\tSummation[j] += PredictedValue;\n",
    "\n",
    "\t\tif (not equallyDiv and batch == NoOfBatches - 1):\n",
    "\t\t\tfor j in range(len(Summation)):\n",
    "\t\t\t\tif j == 0:\n",
    "\t\t\t\t\tCoeff[j] -= (Summation[j] / (len(PriceTrain) % BatchSize)) * LearningRate\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tCoeff[j] = (1 - LearningRate * LambdaParameter / m) * Coeff[j] - (Summation[j] / (len(PriceTrain) % BatchSize)) * LearningRate\n",
    "\t\telse:\n",
    "\t\t\tfor j in range(len(Summation)):\n",
    "\t\t\t\tif j == 0:\n",
    "\t\t\t\t\tCoeff[j] -= (Summation[j] / BatchSize) * LearningRate\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tCoeff[j] = (1 - LearningRate * LambdaParameter / m) * Coeff[j] - (Summation[j] / BatchSize) * LearningRate\n",
    "print(\"Final coefficients are:\")\n",
    "print(Coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute percentage error is : 19.550681895981263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding Mean absolute percentage error.\n",
    "Error = 0\n",
    "for i in range(len(FeaturesTest)):\n",
    "\tpredicted = 0\n",
    "\tfor j in range(len(Coeff)):\n",
    "\t  \tpredicted = predicted + Coeff[j] * FeaturesTest[i][j]\n",
    "\tError += abs(predicted - PriceTest[i]) / PriceTest[i]\n",
    "Error = (Error / len(FeaturesTest)) * 100\n",
    "print(\"Mean absolute percentage error is : \" + str(Error))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(MatrixY, Y_pred):\n",
    "    error = 0\n",
    "    for i in range(len(MatrixY)):\n",
    "        error += abs(MatrixY[i] - Y_pred[i]) / MatrixY[i]\n",
    "    error = error / len(MatrixY)\n",
    "    return error * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(MatrixX, xi, HyperParameterTau):\n",
    "    return np.exp(-np.sum((xi - MatrixX) ** 2, axis = 1) / (2 * HyperParameterTau * HyperParameterTau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LocallyWeightedLR(MatrixX, xi, MatrixY, HyperParameterTau):\n",
    "\tTransposeMatrixX = np.transpose(MatrixX)\n",
    "\tW = kernel(MatrixX, xi, HyperParameterTau)\n",
    "\tMatrixXTransposeW = TransposeMatrixX * W\n",
    "\tMatrixXTransposeWX = np.matmul(MatrixXTransposeW, MatrixX)\n",
    "\tInverseMatrixXTransposeWX = np.linalg.pinv(MatrixXTransposeWX)\n",
    "\tInverseMatrixXTransposeWXMatrixXTransposeW = np.matmul(InverseMatrixXTransposeWX, MatrixXTransposeW)\n",
    "\tInverseMatrixXTransposeWXMatrixXTransposeWY = np.matmul(InverseMatrixXTransposeWXMatrixXTransposeW, MatrixY)\n",
    "\tInverseMatrixXTransposeWXMatrixXTransposeWYTranspose = np.transpose(InverseMatrixXTransposeWXMatrixXTransposeWY)\n",
    "\treturn InverseMatrixXTransposeWXMatrixXTransposeWYTranspose.dot(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = 'https://raw.githubusercontent.com/rishika8910/IML/master/Housing%20Price%20data%20set.csv'\n",
    "input_data = pd.read_csv(dataset_url, usecols = [\"price\", \"lotsize\", \"bedrooms\", \"bathrms\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "FloorArea = input_data['lotsize']\n",
    "NoOfBedrooms = input_data['bedrooms']\n",
    "NoOfBathrooms = input_data['bathrms']\n",
    "MatrixY = input_data['price']\n",
    "MatrixY = np.array(MatrixY)\n",
    "MatrixY = MatrixY.reshape(MatrixY.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing feature scanning on FloorArea\n",
    "FloorArea_Mean = np.mean(FloorArea)\n",
    "FloorArea_Max = max(FloorArea)\n",
    "FloorArea_Min = min(FloorArea)\n",
    "FloorArea_Scaled = []\n",
    "for i in FloorArea:\n",
    "\tFloorArea_Scaled.append((i - FloorArea_Mean) / (FloorArea_Max - FloorArea_Min))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "MatrixX = []\n",
    "for i in range(len(FloorArea)):\n",
    "\tMatrixX.append([1, FloorArea_Scaled[i], NoOfBedrooms[i], NoOfBathrooms[i]])\n",
    "MatrixX = np.array(MatrixX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Locally Weighted Linear Regression for Tau = 5e-05\n",
      "Mean absolute percentage error is : [5.40732413]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HyperParameterTau = 0.00005\n",
    "print(\"Using Locally Weighted Linear Regression for Tau = \" + str(HyperParameterTau))\n",
    "pred = []\n",
    "for i in range(MatrixX.shape[0]):\n",
    "\ty_pred = LocallyWeightedLR(MatrixX, MatrixX[i], MatrixY, HyperParameterTau)\n",
    "\tpred.append(y_pred)\n",
    "print(\"Mean absolute percentage error is : \" + str(calculate_error(MatrixY,pred)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price = input_data['price']\n",
    "\n",
    "#segmenting the features\n",
    "FeaturesTrain = []\n",
    "for i in range(383):\n",
    "\tFeaturesTrain.append([1, FloorArea_Scaled[i], NoOfBedrooms[i], NoOfBathrooms[i]])\n",
    "PriceTrain = Price[:383]\n",
    "PriceTest = []\n",
    "FeaturesTest = []\n",
    "for i in range(383, len(Price)):\n",
    "\tFeaturesTest.append([1, FloorArea_Scaled[i], NoOfBedrooms[i], NoOfBathrooms[i]])\n",
    "\tPriceTest.append(Price[i])\n",
    "m = len(FeaturesTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Slope to find coefficients\n",
    "def Slope(Coeff, FeaturesTrain, PriceTrain, ind):\n",
    "\tError = 0\n",
    "\tfor i in range(len(FeaturesTrain)):\n",
    "\t\titr = 0\n",
    "\t\tfor j in range(len(Coeff)):\n",
    "\t\t\titr = itr + Coeff[j] * FeaturesTrain[i][j]\n",
    "\t\tError += (itr - PriceTrain[i]) * FeaturesTrain[i][ind]\n",
    "\treturn Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scaled batch gradient with regularisation\n",
      "Initial coefficients: \n",
      "[0, 0, 0, 0]\n",
      "Final coefficients are:\n",
      "[5037.585668619078, 11147.667574879839, 10378.580439168689, 22647.298983883848]\n"
     ]
    }
   ],
   "source": [
    "# Using scaled batch gradient with regularisation\n",
    "print(\"Using scaled batch gradient with regularisation\")\n",
    "LearningRate = 0.001\n",
    "LambdaParameter = -49\n",
    "Coeff = [0, 0, 0, 0]\n",
    "print(\"Initial coefficients: \")\n",
    "print(Coeff)\n",
    "for epochs in range(5000):\n",
    "\tTempCoeff = Coeff.copy()\n",
    "\tfor j in range(len(Coeff)):\n",
    "\t\tif (j == 0):\n",
    "\t\t\tTempCoeff[j] = TempCoeff[j] - ((LearningRate / m) * (Slope(Coeff, FeaturesTrain, PriceTrain, j)))\t\n",
    "\t\telse:\n",
    "\t\t\tTempCoeff[j] = (1 - LearningRate * LambdaParameter / m) * TempCoeff[j] - ((LearningRate / m) * (Slope(Coeff, FeaturesTrain, PriceTrain, j)))\n",
    "\tCoeff = TempCoeff.copy()\n",
    "print(\"Final coefficients are:\")\n",
    "print(Coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute percentage error is : 19.92701396456417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding Mean absolute percentage error.\n",
    "Error = 0\n",
    "for i in range(len(FeaturesTest)):\n",
    "\tpredicted = 0\n",
    "\tfor j in range(len(Coeff)):\n",
    "\t  \tpredicted = predicted + Coeff[j] * FeaturesTest[i][j]\n",
    "\tError += abs(predicted - PriceTest[i]) / PriceTest[i]\n",
    "Error = (Error / len(FeaturesTest)) * 100\n",
    "print(\"Mean absolute percentage error is : \" + str(Error))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SlopeStoch(Coeff,FeaturesTrain,ActualVal,ind):\n",
    "\titr = 0\n",
    "\tfor j in range(len(Coeff)):\n",
    "\t\titr = itr + Coeff[j]*FeaturesTrain[j]\n",
    "\treturn (itr - ActualVal) * FeaturesTrain[ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Stochastic gradient with regularisation\n",
      "Initial coefficients: \n",
      "[0, 0, 0, 0]\n",
      "Final coefficients are:\n",
      "[68977.37183533033, 153.6672368058788, 622.1158811423422, 207.34938918615728]\n",
      "Mean absolute percentage error is : 22.392602067246287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using Scaled Stochastic gradient with regularisation.\n",
    "print(\"Using Stochastic gradient with regularisation\")\n",
    "\n",
    "# I tried with different values of tau but found this to be the best.\n",
    "LearningRate = 0.004\n",
    "LambdaParameter = 142000\n",
    "Coeff = [0, 0, 0, 0]\n",
    "print(\"Initial coefficients: \")\n",
    "print(Coeff)\n",
    "\n",
    "for iter in range(10):\n",
    "\tfor i in range(len(PriceTrain)):\n",
    "\t\tTempCoeff = Coeff.copy()\n",
    "\t\tfor j in range(4):\n",
    "\t\t\tif j == 0:\n",
    "\t\t\t\tTempCoeff[j] = TempCoeff[j] - (LearningRate * (SlopeStoch(Coeff, FeaturesTrain[i], PriceTrain[i], j)))\n",
    "\t\t\telse:\n",
    "\t\t\t\tTempCoeff[j] = (1 - LearningRate * LambdaParameter / m) * TempCoeff[j] - (LearningRate * (SlopeStoch(Coeff, FeaturesTrain[i], PriceTrain[i], j)))\n",
    "\t\tCoeff = TempCoeff.copy()\n",
    "\n",
    "print(\"Final coefficients are:\")\n",
    "print(Coeff)\n",
    "\n",
    "# Finding Mean absolute percentage error.\n",
    "Error = 0\n",
    "for i in range(len(FeaturesTest)):\n",
    "\tpredicted = 0\n",
    "\tfor j in range(len(Coeff)):\n",
    "\t  \tpredicted = predicted + Coeff[j] * FeaturesTest[i][j]\n",
    "\tError += abs(predicted - PriceTest[i]) / PriceTest[i]\n",
    "Error = (Error / len(FeaturesTest)) * 100\n",
    "print(\"Mean absolute percentage error is : \" + str(Error))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Scaled Minibatch gradient with regularisation for batch size = 20\n",
      "Final coefficients are:\n",
      "[888.9201243627547, 5168.211726125255, 17701.360814619125, 15202.387873756412]\n",
      "Mean absolute percentage error is : 19.550681895981263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using Scaled Minibatch gradient with regularisation for batch size = 20\n",
    "print(\"Using Scaled Minibatch gradient with regularisation for batch size = 20\")\n",
    "\n",
    "BatchSize = 20;\n",
    "LearningRate = 0.002\n",
    "LambdaParameter = -372\n",
    "Coeff = [0, 0, 0, 0]\n",
    "NoOfBatches = math.ceil(len(PriceTrain) / BatchSize)\n",
    "equallyDiv = False\n",
    "if (len(PriceTrain) % BatchSize == 0):\n",
    "\tequallyDiv = True;\n",
    "\n",
    "for epoch in range(30):\n",
    "\tfor batch in range(NoOfBatches):\n",
    "\t\tSummation = [0, 0, 0, 0]\n",
    "\t\tfor j in range(len(Coeff)):\n",
    "\t\t\tfor i in range(BatchSize):\n",
    "\t\t\t\tif (batch * BatchSize + i == len(FeaturesTrain)):\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\tPredictedValue = 0.0\n",
    "\t\t\t\tfor wj in range(len(Coeff)):\n",
    "\t\t\t\t\tPredictedValue += Coeff[wj] * FeaturesTrain[batch * BatchSize + i][wj]\n",
    "\t\t\t\tPredictedValue -= PriceTrain[batch * BatchSize + i]\n",
    "\t\t\t\tPredictedValue *= FeaturesTrain[batch * BatchSize + i][j]\n",
    "\t\t\t\tSummation[j] += PredictedValue;\n",
    "\n",
    "\t\tif (not equallyDiv and batch == NoOfBatches - 1):\n",
    "\t\t\tfor j in range(len(Summation)):\n",
    "\t\t\t\tif j == 0:\n",
    "\t\t\t\t\tCoeff[j] -= (Summation[j] / (len(PriceTrain) % BatchSize)) * LearningRate\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tCoeff[j] = (1 - LearningRate * LambdaParameter / m) * Coeff[j] - (Summation[j] / (len(PriceTrain) % BatchSize)) * LearningRate\n",
    "\t\telse:\n",
    "\t\t\tfor j in range(len(Summation)):\n",
    "\t\t\t\tif j == 0:\n",
    "\t\t\t\t\tCoeff[j] -= (Summation[j] / BatchSize) * LearningRate\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tCoeff[j] = (1 - LearningRate * LambdaParameter / m) * Coeff[j] - (Summation[j] / BatchSize) * LearningRate\n",
    "print(\"Final coefficients are:\")\n",
    "print(Coeff)\n",
    "\n",
    "# Finding Mean absolute percentage error.\n",
    "Error = 0\n",
    "for i in range(len(FeaturesTest)):\n",
    "\tpredicted = 0\n",
    "\tfor j in range(len(Coeff)):\n",
    "\t  \tpredicted = predicted + Coeff[j] * FeaturesTest[i][j]\n",
    "\tError += abs(predicted - PriceTest[i]) / PriceTest[i]\n",
    "Error = (Error / len(FeaturesTest)) * 100\n",
    "print(\"Mean absolute percentage error is : \" + str(Error))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
